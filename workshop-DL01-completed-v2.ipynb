{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop DL01 - Intro to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "#### Installing TensorFlow\n",
    "1. Open the Anaconda3 Terminal\n",
    "2. Execute `pip install --upgrade tensorflow`\n",
    "\n",
    "#### Getting the MNIST Data\n",
    "1. Go to https://www.kaggle.com/c/digit-recognizer/data\n",
    "2. Download \"train.csv\" and \"test.csv\", put these into the same folder as this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network Image Classifier\n",
    "\n",
    "**Changes from v1**\n",
    "* Added a third FC layer, identifcal to the second\n",
    "* Changed the cost function to softmax_cross_entropy_with_logits; this required transforming the input labels to one hot\n",
    "* Removed the learning rate in the AdamOptimizer, defaults to 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-in raw data\n",
    "data = pd.read_csv(\"datasets/mnist_train.csv\")\n",
    "\n",
    "# mask for splitting data into train and test sets\n",
    "mask = np.random.rand(len(data)) < 0.90\n",
    "\n",
    "# training data, features (X) and labels (y)\n",
    "train_X = data[mask].drop(\"label\", axis=1)\n",
    "train_y = data.label[mask]\n",
    "\n",
    "# test data, features (X) and labels (y)\n",
    "test_X = data[~mask].drop(\"label\", axis=1)\n",
    "test_y = data.label[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for defining weights/biases in tensorflow\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1), shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) define network architecture\n",
    "with tf.name_scope(\"input\"):\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"features\")\n",
    "    y = tf.placeholder(tf.int64, [None], name=\"labels\")\n",
    "    y_one_hot = tf.one_hot(indices=y, depth=10)\n",
    "\n",
    "with tf.name_scope(\"fc-layer-1\"):\n",
    "    w1 = weight_variable([784, 500])\n",
    "    b1 = bias_variable([500])\n",
    "    fc1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "with tf.name_scope(\"fc-layer-2\"):\n",
    "    w2 = weight_variable([500, 500])\n",
    "    b2 = bias_variable([500])\n",
    "    fc2 = tf.nn.relu(tf.matmul(fc1, w2) + b2)\n",
    "    \n",
    "with tf.name_scope(\"fc-layer-3\"):\n",
    "    w3 = weight_variable([500, 500])\n",
    "    b3 = bias_variable([500])\n",
    "    fc3 = tf.nn.relu(tf.matmul(fc2, w3) + b3)\n",
    "    \n",
    "with tf.name_scope(\"output\"):\n",
    "    w4 = weight_variable([500, 10])\n",
    "    b4 = bias_variable([10])\n",
    "    y_ = tf.matmul(fc3, w4) + b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) define loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=y_, labels=y_one_hot)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) define optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(\n",
    "        cross_entropy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aside: evaluation operations\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct = tf.equal(tf.argmax(y_, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Epoch 1 completed, loss = 881.16766\n",
      "Test accuracy = [0.19347826]\n",
      "==================================================\n",
      "Epoch 2 completed, loss = 516.1829\n",
      "Test accuracy = [0.33333334]\n",
      "==================================================\n",
      "Epoch 3 completed, loss = 518.0711\n",
      "Test accuracy = [0.42536232]\n",
      "==================================================\n",
      "Epoch 4 completed, loss = 499.1371\n",
      "Test accuracy = [0.526087]\n",
      "==================================================\n",
      "Epoch 5 completed, loss = 408.74295\n",
      "Test accuracy = [0.5821256]\n",
      "==================================================\n",
      "Epoch 6 completed, loss = 317.60574\n",
      "Test accuracy = [0.6263285]\n",
      "==================================================\n",
      "Epoch 7 completed, loss = 219.16394\n",
      "Test accuracy = [0.6611111]\n",
      "==================================================\n",
      "Epoch 8 completed, loss = 135.15935\n",
      "Test accuracy = [0.70821255]\n",
      "==================================================\n",
      "Epoch 9 completed, loss = 80.794846\n",
      "Test accuracy = [0.74396133]\n",
      "==================================================\n",
      "Epoch 10 completed, loss = 67.62097\n",
      "Test accuracy = [0.7504831]\n",
      "==================================================\n",
      "Epoch 11 completed, loss = 66.16924\n",
      "Test accuracy = [0.7504831]\n",
      "==================================================\n",
      "Epoch 12 completed, loss = 65.22422\n",
      "Test accuracy = [0.73478264]\n",
      "==================================================\n",
      "Epoch 13 completed, loss = 72.17933\n",
      "Test accuracy = [0.7326087]\n",
      "==================================================\n",
      "Epoch 14 completed, loss = 72.17477\n",
      "Test accuracy = [0.7545894]\n",
      "==================================================\n",
      "Epoch 15 completed, loss = 59.44088\n",
      "Test accuracy = [0.797343]\n",
      "==================================================\n",
      "Epoch 16 completed, loss = 44.15338\n",
      "Test accuracy = [0.8335749]\n",
      "==================================================\n",
      "Epoch 17 completed, loss = 32.713814\n",
      "Test accuracy = [0.857971]\n",
      "==================================================\n",
      "Epoch 18 completed, loss = 26.576551\n",
      "Test accuracy = [0.8647343]\n",
      "==================================================\n",
      "Epoch 19 completed, loss = 24.778229\n",
      "Test accuracy = [0.8570048]\n",
      "==================================================\n",
      "Epoch 20 completed, loss = 25.775932\n",
      "Test accuracy = [0.8495169]\n",
      "==================================================\n",
      "Epoch 21 completed, loss = 27.590742\n",
      "Test accuracy = [0.84661835]\n",
      "==================================================\n",
      "Epoch 22 completed, loss = 28.474386\n",
      "Test accuracy = [0.84541065]\n",
      "==================================================\n",
      "Epoch 23 completed, loss = 27.942856\n",
      "Test accuracy = [0.85]\n",
      "==================================================\n",
      "Epoch 24 completed, loss = 26.488235\n",
      "Test accuracy = [0.85603863]\n",
      "==================================================\n",
      "Epoch 25 completed, loss = 24.669962\n",
      "Test accuracy = [0.8603865]\n",
      "==================================================\n",
      "Epoch 26 completed, loss = 22.709784\n",
      "Test accuracy = [0.8673913]\n",
      "==================================================\n",
      "Epoch 27 completed, loss = 20.811224\n",
      "Test accuracy = [0.8763285]\n",
      "==================================================\n",
      "Epoch 28 completed, loss = 19.037092\n",
      "Test accuracy = [0.8816425]\n",
      "==================================================\n",
      "Epoch 29 completed, loss = 17.486048\n",
      "Test accuracy = [0.88454103]\n",
      "==================================================\n",
      "Epoch 30 completed, loss = 16.215359\n",
      "Test accuracy = [0.8888889]\n",
      "==================================================\n",
      "Epoch 31 completed, loss = 15.118826\n",
      "Test accuracy = [0.89178747]\n",
      "==================================================\n",
      "Epoch 32 completed, loss = 14.160972\n",
      "Test accuracy = [0.8934783]\n",
      "==================================================\n",
      "Epoch 33 completed, loss = 13.366116\n",
      "Test accuracy = [0.89710146]\n",
      "==================================================\n",
      "Epoch 34 completed, loss = 12.805479\n",
      "Test accuracy = [0.89879227]\n",
      "==================================================\n",
      "Epoch 35 completed, loss = 12.461353\n",
      "Test accuracy = [0.89975846]\n",
      "==================================================\n",
      "Epoch 36 completed, loss = 12.256257\n",
      "Test accuracy = [0.90144926]\n",
      "==================================================\n",
      "Epoch 37 completed, loss = 12.072446\n",
      "Test accuracy = [0.90507245]\n",
      "==================================================\n",
      "Epoch 38 completed, loss = 11.840458\n",
      "Test accuracy = [0.9057971]\n",
      "==================================================\n",
      "Epoch 39 completed, loss = 11.536135\n",
      "Test accuracy = [0.9062802]\n",
      "==================================================\n",
      "Epoch 40 completed, loss = 11.149892\n",
      "Test accuracy = [0.9074879]\n",
      "==================================================\n",
      "Epoch 41 completed, loss = 10.703673\n",
      "Test accuracy = [0.9074879]\n",
      "==================================================\n",
      "Epoch 42 completed, loss = 10.223724\n",
      "Test accuracy = [0.9074879]\n",
      "==================================================\n",
      "Epoch 43 completed, loss = 9.751314\n",
      "Test accuracy = [0.907971]\n",
      "==================================================\n",
      "Epoch 44 completed, loss = 9.321298\n",
      "Test accuracy = [0.9089372]\n",
      "==================================================\n",
      "Epoch 45 completed, loss = 8.946782\n",
      "Test accuracy = [0.910628]\n",
      "==================================================\n",
      "Epoch 46 completed, loss = 8.614271\n",
      "Test accuracy = [0.9099034]\n",
      "==================================================\n",
      "Epoch 47 completed, loss = 8.300612\n",
      "Test accuracy = [0.9103865]\n",
      "==================================================\n",
      "Epoch 48 completed, loss = 7.9875956\n",
      "Test accuracy = [0.91135263]\n",
      "==================================================\n",
      "Epoch 49 completed, loss = 7.6839604\n",
      "Test accuracy = [0.9123188]\n",
      "==================================================\n",
      "Epoch 50 completed, loss = 7.413114\n",
      "Test accuracy = [0.9137681]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# (4) train network\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # initialize all our operations\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # train the network\n",
    "    print(\"==================================================\")\n",
    "    for epoch in range(50):\n",
    "        \n",
    "        # Note: usually you have to chunk through the data in another\n",
    "        #       for loop; the data here is small though, so you might not\n",
    "        #       have to.\n",
    "        _, epoch_loss = sess.run([optimizer, cross_entropy],\n",
    "                feed_dict={x: train_X, y: train_y})\n",
    "        \n",
    "        print(\"Epoch \" + str(epoch+1) + \" completed, loss = \"\n",
    "              + str(epoch_loss))\n",
    "        \n",
    "        # evaluate on test data\n",
    "        score = sess.run([accuracy],\n",
    "                feed_dict={x: test_X, y: test_y})\n",
    "        print(\"Test accuracy = \" + str(score))\n",
    "        \n",
    "        print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
