{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop DL01 - Intro to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "#### Installing TensorFlow\n",
    "1. Open the Anaconda3 Terminal\n",
    "2. Execute `pip install --upgrade tensorflow`\n",
    "\n",
    "#### Getting the MNIST Data\n",
    "1. Go to https://www.kaggle.com/c/digit-recognizer/data\n",
    "2. Download \"train.csv\" and \"test.csv\", put these into the same folder as this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network Image Classifier\n",
    "\n",
    "The following changes increased test score substantially (from ~70% to 90%+):\n",
    "* Changed cost function to softmax_cross_entropy_with_logits; required transforming input labels to one_hot\n",
    "* Switched learning rate to 0.001 (default for AdamOptimizer)\n",
    "* Changed initialization of weights and biases by using get_variable with xavier_initializer rather than truncated_normal (for weights) and constant (for biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-in raw data\n",
    "data = pd.read_csv(\"datasets/mnist_train.csv\")\n",
    "\n",
    "# mask for splitting data into train and test sets\n",
    "mask = np.random.rand(len(data)) < 0.90\n",
    "\n",
    "# training data, features (X) and labels (y)\n",
    "train_X = data[mask].drop(\"label\", axis=1)\n",
    "train_y = data.label[mask]\n",
    "\n",
    "# test data, features (X) and labels (y)\n",
    "test_X = data[~mask].drop(\"label\", axis=1)\n",
    "test_y = data.label[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) define network architecture\n",
    "with tf.variable_scope(\"all\", reuse=tf.AUTO_REUSE):\n",
    "    \n",
    "    with tf.name_scope(\"input\"):\n",
    "        x = tf.placeholder(tf.float32, [None, 784], name=\"features\")\n",
    "        y = tf.placeholder(tf.int64, [None], name=\"labels\")\n",
    "        y_one_hot = tf.one_hot(indices=y, depth=10)\n",
    "\n",
    "    with tf.name_scope(\"fc-layer-1\"):\n",
    "        w1 = tf.get_variable(name=\"w1\", shape=[784,500],\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b1 = tf.get_variable(name=\"b1\", shape=[500])\n",
    "        fc1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "    with tf.name_scope(\"fc-layer-2\"):\n",
    "        w2 = tf.get_variable(name=\"w2\", shape=[500,500],\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2 = tf.get_variable(name=\"b2\", shape=[500])\n",
    "        fc2 = tf.nn.relu(tf.matmul(fc1, w2) + b2)\n",
    "\n",
    "    with tf.name_scope(\"output\"):\n",
    "        w3 = tf.get_variable(name=\"w3\", shape=[500,10],\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3 = tf.get_variable(name=\"b3\", shape=[10])\n",
    "        y_ = tf.matmul(fc2, w3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) define loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=y_, labels=y_one_hot)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) define optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(\n",
    "        cross_entropy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aside: evaluation operations\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct = tf.equal(tf.argmax(y_, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Epoch 1 completed, loss = 85.27442\n",
      "Test accuracy = [0.21798816]\n",
      "==================================================\n",
      "Epoch 2 completed, loss = 86.67346\n",
      "Test accuracy = [0.30153847]\n",
      "==================================================\n",
      "Epoch 3 completed, loss = 89.09045\n",
      "Test accuracy = [0.44260356]\n",
      "==================================================\n",
      "Epoch 4 completed, loss = 63.186314\n",
      "Test accuracy = [0.61278105]\n",
      "==================================================\n",
      "Epoch 5 completed, loss = 39.160202\n",
      "Test accuracy = [0.65964496]\n",
      "==================================================\n",
      "Epoch 6 completed, loss = 28.862825\n",
      "Test accuracy = [0.6710059]\n",
      "==================================================\n",
      "Epoch 7 completed, loss = 20.810696\n",
      "Test accuracy = [0.728284]\n",
      "==================================================\n",
      "Epoch 8 completed, loss = 13.946636\n",
      "Test accuracy = [0.76449704]\n",
      "==================================================\n",
      "Epoch 9 completed, loss = 9.745537\n",
      "Test accuracy = [0.7635503]\n",
      "==================================================\n",
      "Epoch 10 completed, loss = 9.852828\n",
      "Test accuracy = [0.7443787]\n",
      "==================================================\n",
      "Epoch 11 completed, loss = 11.816876\n",
      "Test accuracy = [0.756213]\n",
      "==================================================\n",
      "Epoch 12 completed, loss = 10.804301\n",
      "Test accuracy = [0.79952663]\n",
      "==================================================\n",
      "Epoch 13 completed, loss = 8.19464\n",
      "Test accuracy = [0.82769233]\n",
      "==================================================\n",
      "Epoch 14 completed, loss = 6.5099053\n",
      "Test accuracy = [0.8421302]\n",
      "==================================================\n",
      "Epoch 15 completed, loss = 5.6846085\n",
      "Test accuracy = [0.85893494]\n",
      "==================================================\n",
      "Epoch 16 completed, loss = 5.1337314\n",
      "Test accuracy = [0.8698225]\n",
      "==================================================\n",
      "Epoch 17 completed, loss = 4.7152324\n",
      "Test accuracy = [0.876213]\n",
      "==================================================\n",
      "Epoch 18 completed, loss = 4.4449544\n",
      "Test accuracy = [0.8764497]\n",
      "==================================================\n",
      "Epoch 19 completed, loss = 4.262353\n",
      "Test accuracy = [0.87810653]\n",
      "==================================================\n",
      "Epoch 20 completed, loss = 4.0716896\n",
      "Test accuracy = [0.88094676]\n",
      "==================================================\n",
      "Epoch 21 completed, loss = 3.8333454\n",
      "Test accuracy = [0.88757396]\n",
      "==================================================\n",
      "Epoch 22 completed, loss = 3.5673254\n",
      "Test accuracy = [0.8894675]\n",
      "==================================================\n",
      "Epoch 23 completed, loss = 3.3067286\n",
      "Test accuracy = [0.8915976]\n",
      "==================================================\n",
      "Epoch 24 completed, loss = 3.0463417\n",
      "Test accuracy = [0.8949112]\n",
      "==================================================\n",
      "Epoch 25 completed, loss = 2.7831252\n",
      "Test accuracy = [0.8989349]\n",
      "==================================================\n",
      "Epoch 26 completed, loss = 2.535221\n",
      "Test accuracy = [0.90343195]\n",
      "==================================================\n",
      "Epoch 27 completed, loss = 2.330084\n",
      "Test accuracy = [0.9046154]\n",
      "==================================================\n",
      "Epoch 28 completed, loss = 2.17958\n",
      "Test accuracy = [0.9043787]\n",
      "==================================================\n",
      "Epoch 29 completed, loss = 2.0758977\n",
      "Test accuracy = [0.9055621]\n",
      "==================================================\n",
      "Epoch 30 completed, loss = 1.9984927\n",
      "Test accuracy = [0.9060355]\n",
      "==================================================\n",
      "Epoch 31 completed, loss = 1.9283755\n",
      "Test accuracy = [0.90674555]\n",
      "==================================================\n",
      "Epoch 32 completed, loss = 1.8478214\n",
      "Test accuracy = [0.90674555]\n",
      "==================================================\n",
      "Epoch 33 completed, loss = 1.7536123\n",
      "Test accuracy = [0.9112426]\n",
      "==================================================\n",
      "Epoch 34 completed, loss = 1.6523451\n",
      "Test accuracy = [0.91360945]\n",
      "==================================================\n",
      "Epoch 35 completed, loss = 1.5523683\n",
      "Test accuracy = [0.9181065]\n",
      "==================================================\n",
      "Epoch 36 completed, loss = 1.4583251\n",
      "Test accuracy = [0.92]\n",
      "==================================================\n",
      "Epoch 37 completed, loss = 1.3740729\n",
      "Test accuracy = [0.9233136]\n",
      "==================================================\n",
      "Epoch 38 completed, loss = 1.2999372\n",
      "Test accuracy = [0.92544377]\n",
      "==================================================\n",
      "Epoch 39 completed, loss = 1.2375928\n",
      "Test accuracy = [0.92591715]\n",
      "==================================================\n",
      "Epoch 40 completed, loss = 1.1891996\n",
      "Test accuracy = [0.92875737]\n",
      "==================================================\n",
      "Epoch 41 completed, loss = 1.1536232\n",
      "Test accuracy = [0.9299408]\n",
      "==================================================\n",
      "Epoch 42 completed, loss = 1.1250721\n",
      "Test accuracy = [0.93278104]\n",
      "==================================================\n",
      "Epoch 43 completed, loss = 1.0969899\n",
      "Test accuracy = [0.9342012]\n",
      "==================================================\n",
      "Epoch 44 completed, loss = 1.0649087\n",
      "Test accuracy = [0.9339645]\n",
      "==================================================\n",
      "Epoch 45 completed, loss = 1.0277168\n",
      "Test accuracy = [0.9344379]\n",
      "==================================================\n",
      "Epoch 46 completed, loss = 0.9869544\n",
      "Test accuracy = [0.93633133]\n",
      "==================================================\n",
      "Epoch 47 completed, loss = 0.9449842\n",
      "Test accuracy = [0.9370414]\n",
      "==================================================\n",
      "Epoch 48 completed, loss = 0.9044471\n",
      "Test accuracy = [0.93869823]\n",
      "==================================================\n",
      "Epoch 49 completed, loss = 0.8677032\n",
      "Test accuracy = [0.9391716]\n",
      "==================================================\n",
      "Epoch 50 completed, loss = 0.83582705\n",
      "Test accuracy = [0.93869823]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# (4) train network\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # initialize all our operations\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # train the network\n",
    "    print(\"==================================================\")\n",
    "    for epoch in range(50):\n",
    "        \n",
    "        # Note: usually you have to chunk through the data in another\n",
    "        #       for loop; the data here is small though, so you might not\n",
    "        #       have to.\n",
    "        _, epoch_loss = sess.run([optimizer, cross_entropy],\n",
    "                feed_dict={x: train_X, y: train_y})\n",
    "        \n",
    "        print(\"Epoch \" + str(epoch+1) + \" completed, loss = \"\n",
    "              + str(epoch_loss))\n",
    "        \n",
    "        # evaluate on test data\n",
    "        score = sess.run([accuracy],\n",
    "                feed_dict={x: test_X, y: test_y})\n",
    "        print(\"Test accuracy = \" + str(score))\n",
    "        \n",
    "        print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
