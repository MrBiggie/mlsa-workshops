{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 01: Introduction to Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helolo\n"
     ]
    }
   ],
   "source": [
    "print(\"helolo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. **Get the data**. Download the Titanic: Machine Learning from Disaster dataset from Kaggle (both \"train.csv\" and \"test.csv\"); put the two files in the same directory as this notebook.\n",
    "2. **Install `pandas`**. Open Anaconda3 navigator, and open the console (Environments --> root). Type `conda install pandas` into the console, and wait for it to install.\n",
    "3. **Install `sklearn`**. The same as in 2, but typing `conda install sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Anatomy\n",
    "\n",
    "**Some basic definitions**. Let's do away with the boring shit first. If we're going to be doing data science, then we need to talk about what a \"dataset\" is.\n",
    "\n",
    "* **Object**, a real-world entity that we describe with data.\n",
    "* **Features**, the properties of an object that we use to describe it.\n",
    "* **Data**, actual measurements of properties of objects.\n",
    "* **Labels**, the category that the object belongs to.\n",
    "* **Dataset**, a set of feature-vectors and associated labels.\n",
    "* **Model**\n",
    "\n",
    "**An example**. Take, for example, an enrollment list for a subject. In this case, each student (corresponding to a row in our list) constitutes an *object*. The *features* that we record for each student might be (for example) \"StudentID\", \"Name\", \"AssignmentMark1\", \"AssignmentMark2\", \"ExamMark\", and \"Passed/Failed\". The values for these features for any given student would constitute the *data* for that student. In this case, let's say that \"Passed/Failed\" is the thing that we want to predict, then \"PassedFailed\" would become our *label*. We could construct some kind of model that takes in a student's \"AssignmentMark1\" and \"AssignmentMark2\" and predicts whether they pass or fail the subject. This could then be used on next-year's student cohort to identify any students in danger of failing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Process\n",
    "\n",
    "The point of this workshop is to give you an idea of what \"doing data science\" actually entails, and then to help you through that process (and some of the tools we could use) on an example data set. This process has roughly five steps:\n",
    "\n",
    "1. **Cleaning** your data;\n",
    "2. **Exploring** your data for interesting patterns;\n",
    "3. **Feature Engineering** to generate new informative features for the data;\n",
    "4. **Modelling** that is building your classifier (using one of the common algorithms); and\n",
    "5. **Explaining** your model (that is, why it works well or poorly).\n",
    "\n",
    "This is obviously a pretty naive workflow, but it gives you a bit of a sense of where to start. In practice, there's a lot of back-and-forth between the steps (especially 2, 3, and 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cleaning\n",
    "\n",
    "When you first get your data, you'll usually find that it's \"unclean\" - that is, not yet suitable to be used in any of our models. This will typically be because there are **missing values**, **anomalously extreme values (outliers)**, or because the **data is non-numeric**. Cleaning means dealing with each of these issues.\n",
    "\n",
    "**Dealing Missing Values & Outliers**\n",
    "* **Ignore them.** This is lightweight and easy, but you'll probably run into issues later on when it comes to training your model (some )\n",
    "Delete the rows with missing/extreme data.\n",
    "* **Delete them.** This saves you from having to deal with null-value errors later on, as well as the implexities of imputation (the next thing), but it's also kind of wasteful.\n",
    "* **Impute them.**\n",
    "\n",
    "**Dealing Non-Numeric**\n",
    "* **Encoding.**\n",
    "\n",
    "### Aside: The Pandas Dataframe\n",
    "\n",
    "If we want to use Python, then we need to get the data into some kind of Python objet to mess around with it. We're going to use the `Dataframe` supplied by the `pandas` module.\n",
    "\n",
    "A `Dataframe` is pretty much the same thing as a table (like in Excel). Columns pertain to features (e.g. age, weight) and rows to data objects (e.g. a person).\n",
    "\n",
    "### Reading the Data\n",
    "```Python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data_file.csv') # read \"data_file.csv\" a Dataframe\n",
    "df.head() # prints first five rows of the dataframe\n",
    "```\n",
    "\n",
    "### Initial Exploration\n",
    "After importing `pandas`, it's good practice to check that everything's been read in correctly, then mess around with it a little to get a sense of what features you have, and how they might be related to the label.\n",
    "\n",
    "```Python\n",
    "df.describe() # generates summary statistics over the data\n",
    "df.info() # prints dataframe metadata\n",
    "\n",
    "df['col_name'].value_counts()\n",
    "pd.crosstab(df['col_name_1'], df['col_name_2'])\n",
    "```\n",
    "\n",
    "### Cleaning the Data\n",
    "\n",
    "**Slicing data by row-index and column-name**. Just like \n",
    "\n",
    "```Python\n",
    "oneCol = df['<column>']\n",
    "twoCols = df[['<col_name_1>', '<col_name_2>']]\n",
    "df.loc[<row_index>]\n",
    "df.iloc[<row_number>]\n",
    "df.at[<row_index>, 'col_name']\n",
    "```\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "Cleaning \n",
    "\n",
    "**Conditional slicing**\n",
    "\n",
    "```Pythnon\n",
    "something\n",
    "\n",
    "```\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "**Finding dirty data**. Finding NaNs and outliers.\n",
    "\n",
    "### \n",
    "\n",
    "**Creating new columns**\n",
    "\n",
    "As with a table, it's possible to look up data by-column or by-row really easily with a dataframe. Use something akin to the following code to read data. You can use any of the following methods to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "**Primary**. We're going to start off by reading and messing around with our data. Move the \"data.csv\" into the same directory as this Jupyter Notebook.\n",
    "1. Read the data (check that it's been read correctly).\n",
    "2. Familiarise yourself with the data a little more.\n",
    "2. Clean the data (we want a Dataframe that has no missing values).\n",
    "\n",
    "**Additional**. \n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelling/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes\n",
    "\n",
    "`df = pd.read_csv(<path_to_data_file>)`  \n",
    "`df.head()`  \n",
    "`df.describe()`  \n",
    "`df[<column_name>]`\n",
    "`df[]`\n",
    "\n",
    "**Reading data into pandas dataframes**  \n",
    "Raw data is typically stored either in files (like .csv) or in some kind of database. If we want to use Python to manipulate that data, however, we need to read it into some kind of idiomatic data structure - pandas provides the `dataframe` object for this purpose. **some explanation of what a dataframe object is**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex Embarked\n",
       "0     male        S\n",
       "1   female        C\n",
       "2   female        S\n",
       "3   female        S\n",
       "4     male        S\n",
       "5     male        Q\n",
       "6     male        S\n",
       "7     male        S\n",
       "8   female        S\n",
       "9   female        C\n",
       "10  female        S"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data into pandas dataframe\n",
    "df = pd.read_csv(\"datasets/titanic_train.csv\")\n",
    "\n",
    "# print out the \"head\" (first five rows) to check it's been properly imported\n",
    "df.at[0, 'Sex']\n",
    "df.loc[0:10, ['Sex', 'Embarked']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating new columns**  \n",
    "The raw data you read directly into pandas dataframes will pretty much always be \"unclean\" (i.e. unsuitable for consumption by a model). This is likely because (1) the data is non-numeric or non-boolean (especially in the case of strings like the \"Name\" feature of this dataframe), (2) some of the data is missing, and/or (3) some of the data has been entered input erroneously. Forget about (2) and (3) for the moment; let's focus on (1).\n",
    "\n",
    "Firstly, notice that values for the \"Sex\" feature are represented as strings (\"male\" and \"female\"). The problem with this is that the string cannot be consumed by most models (e.g. k-nearest neighbours). Since it's a binary feature (i.e. only takes two possible values), we can encode it as a new binary feature that takes the value 1 if \"Sex\" is \"male\", and 0 if \"female\".\n",
    "\n",
    "Let's do the same with \"Embarked\" (embarkation location). Since \"Embarked\" can take three values, \"C\", \"Q\", and \"S\", we'll need to encode the strings using either (1) three binary variables (\"EmbarkedAtC\", \"EmbarkedAtQ\", or \"EmbarkedAtS\") or (2) a simple numerical mapping (C->1, Q->2, S->3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>EmbarkedEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  IsMale  EmbarkedEncoded  \n",
       "0      0         A/5 21171   7.2500   NaN        S       1                3  \n",
       "1      0          PC 17599  71.2833   C85        C       0                1  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S       0                3  \n",
       "3      0            113803  53.1000  C123        S       0                3  \n",
       "4      0            373450   8.0500   NaN        S       1                3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to transform one of the values from \"Sex\" into a binary digit\n",
    "def binarize_sex(sex):\n",
    "    if sex == \"male\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# create a new column \"IsMale\" by 'applying' binarize_sex to each row of the \"Sex\" column\n",
    "df[\"IsMale\"] = df[\"Sex\"].apply(binarize_sex)\n",
    "\n",
    "# do the same for \"Embarked\"\n",
    "def encode_embarked(emb):\n",
    "    if emb == \"C\":\n",
    "        return 1\n",
    "    elif emb == \"Q\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df[\"EmbarkedEncoded\"] = df[\"Embarked\"].apply(encode_embarked)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features \"SibSp\" (number of siblings or spouses) and \"Parch\" (number of parents or children) are sort of hard to understand when taken alone. Let's try to aggregate the two features into a single feature, \"CountFamily\" (number of family members)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>EmbarkedEncoded</th>\n",
       "      <th>CountFamily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  IsMale  EmbarkedEncoded  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S       1                3   \n",
       "1      0          PC 17599  71.2833   C85        C       0                1   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S       0                3   \n",
       "3      0            113803  53.1000  C123        S       0                3   \n",
       "4      0            373450   8.0500   NaN        S       1                3   \n",
       "\n",
       "   CountFamily  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate new column \"CountFamily\" via element-wise summation of \"SibSp\" and \"Parch\"\n",
    "df[\"CountFamily\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping existing columns**  \n",
    "At this point, we want to drop all the features that we're not going to use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>EmbarkedEncoded</th>\n",
       "      <th>CountFamily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age     Fare  IsMale  EmbarkedEncoded  \\\n",
       "0            1         0       3  22.0   7.2500       1                3   \n",
       "1            2         1       1  38.0  71.2833       0                1   \n",
       "2            3         1       3  26.0   7.9250       0                3   \n",
       "3            4         1       1  35.0  53.1000       0                3   \n",
       "4            5         0       3  35.0   8.0500       1                3   \n",
       "\n",
       "   CountFamily  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the columns\n",
    "#   inplace=True, change the dataframe object in-place, rather than returning a copy\n",
    "#   axis=1, perform the operation on the column axis (1) rather than the row axis (default, 0)\n",
    "df.drop([\"Name\", \"Sex\", \"SibSp\", \"Parch\", \"Ticket\", \"Cabin\", \"Embarked\"], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing-out to data file**  \n",
    "So you're done cleaning your data. Now we either want to (1) pass it straight into a model or (2) save it in its clean form on the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe to csv\n",
    "#  index=False, don't write-out with an index column, since our dataframe already has one (the unnamed leftmost column)\n",
    "df.to_csv(\"datasets/titanic_train_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Write a *function* which takes a raw dataframe (from the titanic dataset) and returns a clean dataframe (like the one generated above). Try it on the file \"datasets/titanic_test.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>EmbarkedEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>2</td>\n",
       "      <td>63.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.1708</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>61.3792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>3</td>\n",
       "      <td>22.5</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass   Age      Fare  IsMale  EmbarkedEncoded\n",
       "0            892       3  34.5    7.8292       1                2\n",
       "1            893       3  47.0    7.0000       0                3\n",
       "2            894       2  62.0    9.6875       1                2\n",
       "3            895       3  27.0    8.6625       1                3\n",
       "4            896       3  22.0   12.2875       0                3\n",
       "5            897       3  14.0    9.2250       1                3\n",
       "6            898       3  30.0    7.6292       0                2\n",
       "7            899       2  26.0   29.0000       1                3\n",
       "8            900       3  18.0    7.2292       0                1\n",
       "9            901       3  21.0   24.1500       1                3\n",
       "10           902       3   NaN    7.8958       1                3\n",
       "11           903       1  46.0   26.0000       1                3\n",
       "12           904       1  23.0   82.2667       0                3\n",
       "13           905       2  63.0   26.0000       1                3\n",
       "14           906       1  47.0   61.1750       0                3\n",
       "15           907       2  24.0   27.7208       0                1\n",
       "16           908       2  35.0   12.3500       1                2\n",
       "17           909       3  21.0    7.2250       1                1\n",
       "18           910       3  27.0    7.9250       0                3\n",
       "19           911       3  45.0    7.2250       0                1\n",
       "20           912       1  55.0   59.4000       1                1\n",
       "21           913       3   9.0    3.1708       1                3\n",
       "22           914       1   NaN   31.6833       0                3\n",
       "23           915       1  21.0   61.3792       1                1\n",
       "24           916       1  48.0  262.3750       0                1\n",
       "25           917       3  50.0   14.5000       1                3\n",
       "26           918       1  22.0   61.9792       0                1\n",
       "27           919       3  22.5    7.2250       1                1\n",
       "28           920       1  41.0   30.5000       1                3\n",
       "29           921       3   NaN   21.6792       1                1\n",
       "..           ...     ...   ...       ...     ...              ...\n",
       "388         1280       3  21.0    7.7500       1                2\n",
       "389         1281       3   6.0   21.0750       1                3\n",
       "390         1282       1  23.0   93.5000       1                3\n",
       "391         1283       1  51.0   39.4000       0                3\n",
       "392         1284       3  13.0   20.2500       1                3\n",
       "393         1285       2  47.0   10.5000       1                3\n",
       "394         1286       3  29.0   22.0250       1                3\n",
       "395         1287       1  18.0   60.0000       0                3\n",
       "396         1288       3  24.0    7.2500       1                2\n",
       "397         1289       1  48.0   79.2000       0                1\n",
       "398         1290       3  22.0    7.7750       1                3\n",
       "399         1291       3  31.0    7.7333       1                2\n",
       "400         1292       1  30.0  164.8667       0                3\n",
       "401         1293       2  38.0   21.0000       1                3\n",
       "402         1294       1  22.0   59.4000       0                1\n",
       "403         1295       1  17.0   47.1000       1                3\n",
       "404         1296       1  43.0   27.7208       1                1\n",
       "405         1297       2  20.0   13.8625       1                1\n",
       "406         1298       2  23.0   10.5000       1                3\n",
       "407         1299       1  50.0  211.5000       1                1\n",
       "408         1300       3   NaN    7.7208       0                2\n",
       "409         1301       3   3.0   13.7750       0                3\n",
       "410         1302       3   NaN    7.7500       0                2\n",
       "411         1303       1  37.0   90.0000       0                2\n",
       "412         1304       3  28.0    7.7750       0                3\n",
       "413         1305       3   NaN    8.0500       1                3\n",
       "414         1306       1  39.0  108.9000       0                1\n",
       "415         1307       3  38.5    7.2500       1                3\n",
       "416         1308       3   NaN    8.0500       1                3\n",
       "417         1309       3   NaN   22.3583       1                1\n",
       "\n",
       "[418 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/titanic_train.csv\")\n",
    "def clean_titanic(df):\n",
    "    df[\"IsMale\"] = df[\"Sex\"].apply(binarize_sex)\n",
    "    df[\"EmbarkedEncoded\"] = df[\"Embarked\"].apply(encode_embarked)\n",
    "    df.drop([\"Name\", \"Sex\", \"SibSp\", \"Parch\", \"Ticket\", \"Cabin\", \"Embarked\"], inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "# test clean_titanic\n",
    "clean_titanic(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removed\n",
    "\n",
    "## 1. Introduction to Data Science\n",
    "\n",
    "### Data Science Paradigms\n",
    "\n",
    "The kinds of problems that we're interested in in data science can be split (crudely) into two categories: supervised learning, and unsupervised learning.\n",
    "* **Supervised Learning**. Given set of input variables, X (features), with corresponding output variables y (labels), come up with some kind of function that maps X to y. For example, you might be given a data set of people's ages, weights, and heights (the features), and their associated sexes (the labels); under a supervised learning paradigm, we try to build a model trys to predict a person's sex given their age, weight, and height.\n",
    "* **Unsupervised Learning**. Given a set of input variables, X, learn the underlying distribution of the data. \"Learning the underlying distribution\" of the data is a fancy way of saying \"find records that are either similar to or associated with each other\" in some way. Notice that this sounds a lot more open-ended than supervised learning. That's mainly because - in this case - we're not given any notion of \"truth\" (i.e. a label) that we're trying to guess at. It's our job to actually discover patterns in the data.\n",
    "\n",
    "We'll motivate this workshop under **supervised learning** paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
