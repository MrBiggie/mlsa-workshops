{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop DL01 - Intro to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "\n",
    "#### Installing TensorFlow\n",
    "1. Open the Anaconda3 Terminal\n",
    "2. Execute `pip install --upgrade tensorflow`\n",
    "\n",
    "#### Getting the MNIST Data\n",
    "1. Go to https://www.kaggle.com/c/digit-recognizer/data\n",
    "2. Download \"train.csv\" and \"test.csv\", put these into the same folder as this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-in raw data\n",
    "data = pd.read_csv(\"datasets/mnist_train.csv\")\n",
    "\n",
    "# mask for splitting data into train and test sets\n",
    "mask = np.random.rand(len(data)) < 0.90\n",
    "\n",
    "# training data, features (X) and labels (y)\n",
    "train_X = data[mask].drop(\"label\", axis=1)\n",
    "train_y = data.label[mask]\n",
    "\n",
    "# test data, features (X) and labels (y)\n",
    "test_X = data[~mask].drop(\"label\", axis=1)\n",
    "test_y = data.label[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for defining weights/biases in tensorflow\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1), shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) define network architecture\n",
    "with tf.name_scope(\"input\"):\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"features\")\n",
    "    y = tf.placeholder(tf.int64, [None], name=\"labels\")\n",
    "\n",
    "with tf.name_scope(\"fc-layer-1\"):\n",
    "    w1 = weight_variable([784, 500])\n",
    "    b1 = bias_variable([500])\n",
    "    fc1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "with tf.name_scope(\"fc-layer-2\"):\n",
    "    w2 = weight_variable([500, 500])\n",
    "    b2 = bias_variable([500])\n",
    "    fc2 = tf.nn.relu(tf.matmul(fc1, w2) + b2)\n",
    "    \n",
    "with tf.name_scope(\"output\"):\n",
    "    w3 = weight_variable([500, 10])\n",
    "    b3 = bias_variable([10])\n",
    "    y_ = tf.matmul(fc2, w3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) define loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    cross_entropy = tf.losses.sparse_softmax_cross_entropy(\n",
    "        labels=y, logits=y_\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) define optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(\n",
    "        cross_entropy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aside: evaluation operations\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct = tf.equal(tf.argmax(y_, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed, loss = 569.14136\n",
      "Epoch 1 completed, loss = 2968.1665\n"
     ]
    }
   ],
   "source": [
    "# (4) train network\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # initialize all our operations\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # train the network\n",
    "    for epoch in range(20):\n",
    "        \n",
    "        # Note: usually you have to chunk through the data in another\n",
    "        #       for loop; the data here is small though, so you might not\n",
    "        #       have to.\n",
    "        _, epoch_loss = sess.run([optimizer, cross_entropy],\n",
    "                feed_dict={x: train_X, y: train_y})\n",
    "        \n",
    "        print(\"Epoch \" + str(epoch) + \" completed, loss = \"\n",
    "              + str(epoch_loss))\n",
    "        \n",
    "    # evaluate on the test data\n",
    "    print(\"==================================================\")\n",
    "    score = sess.run([accuracy],\n",
    "                feed_dict={x: test_X, y: test_y})\n",
    "    print(\"Test accuracy = \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
